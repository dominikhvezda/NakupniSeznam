import Foundation
import Speech
import AVFoundation
import Combine

/// T콏칤da pro rozpozn치v치n칤 캜esk칠 콏e캜i pomoc칤 Speech Framework
class SpeechRecognizer: ObservableObject {
    @Published var transcript = ""
    @Published var isRecording = false
    @Published var authorizationStatus: SFSpeechRecognizerAuthorizationStatus = .notDetermined

    private var audioEngine: AVAudioEngine?
    private var request: SFSpeechAudioBufferRecognitionRequest?
    private var task: SFSpeechRecognitionTask?
    private let recognizer: SFSpeechRecognizer?

    init() {
        recognizer = SFSpeechRecognizer(locale: Locale(identifier: "cs-CZ"))
        authorizationStatus = SFSpeechRecognizer.authorizationStatus()
        print("游꿗 SpeechRecognizer initialized, status: \(authorizationStatus.rawValue)")
    }

    deinit {
        print("游꿗 SpeechRecognizer deallocating")
        cleanupSync()
    }

    func requestAuthorization() async {
        print("游꿗 Requesting authorization...")
        let currentStatus = SFSpeechRecognizer.authorizationStatus()

        await MainActor.run {
            self.authorizationStatus = currentStatus
        }

        if currentStatus == .notDetermined {
            let newStatus = await withCheckedContinuation { continuation in
                SFSpeechRecognizer.requestAuthorization { status in
                    print("游꿗 Authorization result: \(status.rawValue)")
                    continuation.resume(returning: status)
                }
            }

            await MainActor.run {
                self.authorizationStatus = newStatus
            }
        }
    }

    func startRecording() {
        print("游꿗 startRecording called, current status: \(authorizationStatus.rawValue)")

        // Pokud je코t캩 nem치me opr치vn캩n칤, vy쮂멳치me ho
        if authorizationStatus == .notDetermined {
            print("游꿗 Authorization not determined, requesting...")
            Task {
                await requestAuthorization()
                // Po z칤sk치n칤 opr치vn캩n칤 znovu zavol치me startRecording
                if authorizationStatus == .authorized {
                    print("游꿗 Authorization granted, starting recording...")
                    startRecording()
                } else {
                    print("游꿗 Authorization denied: \(authorizationStatus.rawValue)")
                }
            }
            return
        }

        guard let recognizer = recognizer, recognizer.isAvailable else {
            print("游꿗 ERROR: Speech recognizer not available")
            return
        }

        guard authorizationStatus == .authorized else {
            print("游꿗 ERROR: Not authorized for speech recognition: \(authorizationStatus.rawValue)")
            return
        }

        // Zastav칤me p콏edchoz칤 nahr치v치n칤, pokud b캩쮂
        if isRecording {
            print("游꿗 Already recording, stopping first...")
            stopRecording()
        }

        do {
            print("游꿗 Setting up audio session...")
            // Nastaven칤 audio session
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)

            print("游꿗 Creating audio engine...")
            // Vytvo콏en칤 nov칠ho audio enginu
            audioEngine = AVAudioEngine()
            guard let audioEngine = audioEngine else {
                print("游꿗 ERROR: Failed to create audio engine")
                return
            }

            print("游꿗 Creating recognition request...")
            // Vytvo콏en칤 recognition requestu
            request = SFSpeechAudioBufferRecognitionRequest()
            guard let request = request else {
                print("游꿗 ERROR: Failed to create recognition request")
                return
            }
            request.shouldReportPartialResults = true

            print("游꿗 Starting recognition task...")
            // FIXED: Use existing recognizer instead of creating new one (memory leak!)
            task = recognizer.recognitionTask(with: request) { [weak self] result, error in
                guard let self = self else { return }

                if let result = result {
                    let transcriptText = result.bestTranscription.formattedString
                    Task { @MainActor in
                        self.transcript = transcriptText
                        print("游꿗 Transcript: \(transcriptText)")
                    }
                }

                if let error = error {
                    print("游꿗 Recognition error: \(error.localizedDescription)")
                    Task { @MainActor in
                        self.stopRecording()
                    }
                }

                if result?.isFinal == true {
                    print("游꿗 Recognition final")
                    Task { @MainActor in
                        self.stopRecording()
                    }
                }
            }

            print("游꿗 Installing audio tap...")
            // Za캜neme nahr치vat z mikrofonu
            let recordingFormat = audioEngine.inputNode.outputFormat(forBus: 0)
            audioEngine.inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak request] buffer, _ in
                request?.append(buffer)
            }

            print("游꿗 Starting audio engine...")
            audioEngine.prepare()
            try audioEngine.start()

            DispatchQueue.main.async {
                self.transcript = ""
                self.isRecording = true
                print("游꿗 Recording started successfully!")
            }

        } catch {
            print("游꿗 ERROR: Failed to start recording: \(error.localizedDescription)")
            cleanupSync()
        }
    }

    func stopRecording() {
        print("游꿗 stopRecording called")
        cleanupSync()
        DispatchQueue.main.async {
            self.isRecording = false
        }
    }

    private func cleanupSync() {
        print("游꿗 Cleaning up resources...")

        // Stop and cleanup audio engine
        if let audioEngine = audioEngine {
            if audioEngine.isRunning {
                audioEngine.stop()
            }
            audioEngine.inputNode.removeTap(onBus: 0)
        }

        // End audio request
        request?.endAudio()

        // Cancel recognition task
        task?.cancel()

        // Release resources
        audioEngine = nil
        request = nil
        task = nil

        // Deactivate audio session
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
            print("游꿗 Audio session deactivated")
        } catch {
            print("游꿗 Warning: Failed to deactivate audio session: \(error.localizedDescription)")
        }

        print("游꿗 Cleanup complete")
    }

    func reset() {
        DispatchQueue.main.async {
            self.transcript = ""
        }
        print("游꿗 Transcript reset")
    }
}
